# Default values for aladdin
# This is a YAML-formatted file.

# ============================================================================
# Console Plugin Configuration
# ============================================================================
plugin:
  # Plugin name - used for ConsolePlugin resource and service names
  name: "genie-web-client"
  description: ""
  image: ""
  imagePullPolicy: Always
  imagePullSecrets: []
  replicas: 2
  port: 9443
  securityContext:
    enabled: true
  podSecurityContext:
    enabled: true
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
  containerSecurityContext:
    enabled: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
  resources:
    requests:
      cpu: 10m
      memory: 50Mi
  basePath: /
  certificateSecretName: ""
  serviceAccount:
    create: true
    annotations: {}
    name: ""
  patcherServiceAccount:
    create: true
    annotations: {}
    name: ""
  jobs:
    patchConsoles:
      enabled: true
      image: "registry.redhat.io/openshift4/ose-tools-rhel9@sha256:ee65b244fc94d5765514c604dc0a288517dcdce68de65128d047622b6b30a618"
      podSecurityContext:
        enabled: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      containerSecurityContext:
        enabled: true
        allowPrivilegeEscalation: false
        capabilities:
          drop:
            - ALL
      resources:
        requests:
          cpu: 10m
          memory: 50Mi

# ConsolePlugin patch configuration
# Patches the ConsolePlugin to point the "ols" proxy to the configured backend service (OLS or LCORE)
consolePluginPatch:
  # Service to point the proxy to when using lightspeedCore
  lcoreTargetService:
    name: lightspeed-core
    namespace: openshift-aladdin
    port: 8443
  # Service to point the proxy to when using OLS
  olsTargetService:
    name: lightspeed-app-server
    namespace: openshift-lightspeed
    port: 8443


# ============================================================================
# Backend Services Configuration
# ============================================================================

# Obs MCP Server configuration
obsMcp:
  enabled: true
  image:
    repository: quay.io/bparees/obs-mcp
    tag: latest
    pullPolicy: Always
  service:
    port: 8080
  replicas: 1
  args:
    - "-auth-mode"
    - "header"
  # Prometheus URL for metrics queries
  prometheusUrl: "https://prometheus-k8s.openshift-monitoring.svc:9091"

# Kubernetes MCP Server configuration
# Note: k8s MCP server is only deployed when lightspeedCore.enabled is true
k8sMcp:
  image:
    repository: quay.io/bparees/k8s-mcp
    tag: latest
    pullPolicy: Always
  service:
    port: 8080
    targetPort: 8080
  containerPort: 8080
  replicas: 1
  args:
    - "--read-only"
    - "--toolsets"
    - "core"
    - "--log-level"
    - "8"

# NextGenUI MCP Server configuration
nguiMcp:
  enabled: true
  image:
    repository: quay.io/bparees/ngui-mcp
    tag: latest
    pullPolicy: Always
  service:
    port: 9200
  containerPort: 9200
  replicas: 1
  # API key for NGUI provider (OpenAI compatible)
  # This should be overridden via --set or values file
  apiKey: ""
  secretName: ngui-llm-api-key
  configMapName: ngui-mcp-config
  env:
    model: "gpt-4.1-nano"
    tools: "generate_ui_component"
    structuredOutputEnabled: "false"

# Lightspeed Core configuration
lightspeedCore:
  enabled: false
  # LLM configuration
  llm:
    # LLM API key (required)
    apiKey: ""
    # Secret name for the API key
    apiKeySecretName: lcore-llm-api-key
  image:
    repository: quay.io/bparees/lightspeed-core
    tag: latest
    pullPolicy: Always
  service:
    port: 8443
  containerPort: 8443
  replicas: 1
  # TLS secret name (auto-generated by OpenShift service serving certs)
  tlsSecretName: lightspeed-core-tls
  # ConfigMap names
  runConfigMapName: llamastack-run
  stackConfigMapName: lightspeed-stack
  # Inference settings
  inference:
    defaultModel: gpt-4o-mini
    defaultProvider: openai
  # MCP servers configuration
  mcpServers:
    - name: obs
      url: "http://genie-obs-mcp-server.openshift-aladdin:8080/mcp"
      authorization_headers:
        Authorization: "kubernetes"    # Uses user's k8s token from request auth
    - name: kube
      url: "http://mcp-kubernetes-svc:8080/mcp"
      authorization_headers:
        Authorization: "kubernetes"    # Uses user's k8s token from request auth
    - name: ngui
      url: "http://ngui-mcp.openshift-aladdin:9200/mcp"
      authorization_headers:
        Authorization: "kubernetes"    # Uses user's k8s token from request auth
  # LlamaStack run.yaml configuration
  models:
    providerId: openai
    providerType: remote::openai
    modelId: gpt-4o-mini
    modelType: llm
    providerModelId: gpt-4o-mini

# OLS Subscription configuration
# Creates a Subscription for the Lightspeed operator
olsSubscription:
  name: lightspeed-operator
  namespace: openshift-lightspeed
  channel: stable
  installPlanApproval: Automatic
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  # startingCSV: lightspeed-operator.v1.0.9
  # OperatorGroup configuration
  # operatorGroupName defaults to namespace if not specified
  operatorGroupName: openshift-lightspeed
  # targetNamespaces defines which namespaces the operator watches
  # Empty list = AllNamespaces mode (cluster-scoped)
  # Single namespace = OwnNamespace mode
  # Multiple namespaces = MultiNamespace mode
  targetNamespaces: ["openshift-lightspeed"]

# OLSConfig configuration
# Creates an OLSConfig custom resource for the Lightspeed operator
olsConfig:
  enabled: true
  llm:
    # LLM API key (required)
    apiKey: ""
    # Secret name for the API key
    apiKeySecretName: ols-llm-api-key
    providers:
      - credentialsSecretName: ols-llm-api-key
        models:
          - gpt-4o-mini
        name: OpenAI
        type: openai
        url: "https://api.openai.com/v1"
  ols:
    defaultModel: gpt-4o-mini
    defaultProvider: OpenAI
  mcpServers:
    obs:
      url: "http://genie-obs-mcp-server.openshift-aladdin:8080/mcp"
    # - name: kube
    #   url: "http://mcp-kubernetes-svc:8080/mcp"
    ngui:
      url: "http://ngui-mcp.openshift-aladdin:9200/mcp"

